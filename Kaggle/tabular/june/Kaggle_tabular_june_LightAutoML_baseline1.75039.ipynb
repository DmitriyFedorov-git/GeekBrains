{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_tabular_june_LightAutoML_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4tUBSDwIHNo"
      },
      "source": [
        "Код отсюда: https://www.kaggle.com/alexryzhkov/lightautoml-baseline-tps-june-2021\n",
        "\n",
        "Туториал по lightautoml https://lightautoml.readthedocs.io/en/latest/tutorials/tutor_2.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioxKaRoEGGd2",
        "outputId": "83820a01-d100-4d94-963f-67113d65892f"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c tabular-playground-series-jun-2021\n",
        "!pip install catboost\n",
        "!pip install eli5\n",
        "!pip install shap\n",
        "!unzip /content/test.csv.zip\n",
        "!unzip /content/train.csv.zip\n",
        "!unzip /content/sample_submission.csv.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content\n",
            "  0% 0.00/3.14M [00:00<?, ?B/s]\n",
            "100% 3.14M/3.14M [00:00<00:00, 105MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            "  0% 0.00/6.49M [00:00<?, ?B/s]\n",
            "100% 6.49M/6.49M [00:00<00:00, 107MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/264k [00:00<?, ?B/s]\n",
            "100% 264k/264k [00:00<00:00, 84.9MB/s]\n",
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/80/8e9c57ec32dfed6ba2922bc5c96462cbf8596ce1a6f5de532ad1e43e53fe/catboost-0.25.1-cp37-none-manylinux1_x86_64.whl (67.3MB)\n",
            "\u001b[K     |████████████████████████████████| 67.3MB 48kB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.25.1\n",
            "Collecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/54/04cab6e1c0ae535bec93f795d8403fdf6caf66fa5a6512263202dbb14ea6/eli5-0.11.0-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 28.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (21.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.8.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from eli5) (2.11.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->eli5) (2.0.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.11.0\n",
            "Collecting shap\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/f4/c5b95cddae15be80f8e58b25edceca105aa83c0b8c86a1edad24a6af80d3/shap-0.39.0.tar.gz (356kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 20.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.41.1)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/78/c2/b3f55dfdb8af9812fdb9baf70cacf3b9e82e505b2bd4324d588888b81202/slicer-0.0.7-py3-none-any.whl\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.0.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Building wheels for collected packages: shap\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491617 sha256=170015f47e708ae08ce788c605b317fcbfbe4b72942354ba443643b056adc3a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/27/f5/a8ab9da52fd159aae6477b5ede6eaaec69fd130fa0fa59f283\n",
            "Successfully built shap\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.39.0 slicer-0.0.7\n",
            "Archive:  /content/test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  /content/train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  /content/sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EGHFVYpHv9j",
        "outputId": "ef60cca3-5038-49a2-a997-4b8a6cb7bb19"
      },
      "source": [
        "!pip install -U lightautoml"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lightautoml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/b7/eddea00dbc08237ba75d0bff3926def73e3be81afc3d2e9f4652c24fd1e8/LightAutoML-0.2.14-py3-none-any.whl (250kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 31.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.7/dist-packages (from lightautoml) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from lightautoml) (4.41.1)\n",
            "Collecting lightgbm<3.0,>=2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/9d/ddcb2f43aca194987f1a99e27edf41cf9bc39ea750c3371c2a62698c509a/lightgbm-2.3.1-py2.py3-none-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 30.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: webencodings in /usr/local/lib/python3.7/dist-packages (from lightautoml) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: pywavelets in /usr/local/lib/python3.7/dist-packages (from lightautoml) (1.1.1)\n",
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/21/d13081805e1e1afc71f5bb743ece324c8bd576237c51b899ecb38a717502/optuna-2.7.0-py3-none-any.whl (293kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 47.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from lightautoml) (3.13)\n",
            "Collecting transformers>=4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: seaborn in /usr/local/lib/python3.7/dist-packages (from lightautoml) (0.11.1)\n",
            "Collecting poetry-core<2.0.0,>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/e1/08c7478df1e93dea47b06c9d9a80dbb54af7421462e1b22c280d063df807/poetry_core-1.0.3-py2.py3-none-any.whl (424kB)\n",
            "\u001b[K     |████████████████████████████████| 430kB 46.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.7/dist-packages (from lightautoml) (2.5.1)\n",
            "Collecting json2html\n",
            "  Downloading https://files.pythonhosted.org/packages/01/d5/40b617ee19d2d79f606ed37f8a81e51158f126d2af67270c68f2b47ae0d5/json2html-1.3.0.tar.gz\n",
            "Collecting importlib-metadata<2.0,>=1.0; python_version < \"3.8\"\n",
            "  Downloading https://files.pythonhosted.org/packages/8e/58/cdea07eb51fc2b906db0968a94700866fc46249bdc75cac23f9d13168929/importlib_metadata-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from lightautoml) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from lightautoml) (1.8.1+cu101)\n",
            "Collecting autowoe>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/5e/5be453ce2daa804b09d5b2cd9c2819f449a163cb227c8b8172479388f4f4/AutoWoE-1.2.5-py3-none-any.whl (204kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 54.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-image in /usr/local/lib/python3.7/dist-packages (from lightautoml) (0.16.2)\n",
            "Collecting log-calls\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/e4/0163ac51514932824ae8962a2852ff46971aeed2e2a3dbd8717aaa8ace1a/log_calls-0.3.2.tar.gz (232kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 43.3MB/s \n",
            "\u001b[?25hCollecting cmaes\n",
            "  Downloading https://files.pythonhosted.org/packages/01/1f/43b01223a0366171f474320c6e966c39a11587287f098a5f09809b45e05f/cmaes-0.8.2-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: holidays in /usr/local/lib/python3.7/dist-packages (from lightautoml) (0.10.5.2)\n",
            "Collecting albumentations>=0.4.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/be/3db3cd8af771988748f69eace42047d5edebf01eaa7e1293f3b3f75f989e/albumentations-1.0.0-py3-none-any.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: gensim in /usr/local/lib/python3.7/dist-packages (from lightautoml) (3.6.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from lightautoml) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from lightautoml) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: torchvision in /usr/local/lib/python3.7/dist-packages (from lightautoml) (0.9.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from lightautoml) (2.11.3)\n",
            "Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.7/dist-packages (from lightautoml) (4.1.2.30)\n",
            "Requirement already satisfied, skipping upgrade: catboost in /usr/local/lib/python3.7/dist-packages (from lightautoml) (0.25.1)\n",
            "Collecting efficientnet-pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/a0/dd40b50aebf0028054b6b35062948da01123d7be38d08b6b1e5435df6363/efficientnet_pytorch-0.7.1.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from lightautoml) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=1 in /usr/local/lib/python3.7/dist-packages (from lightautoml) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk->lightautoml) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna->lightautoml) (1.4.15)\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/32/e6/e9ddc6fa1104fda718338b341e4b3dc31cd8039ab29e52fc73b508515361/colorlog-5.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna->lightautoml) (20.9)\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/80/ef186e599a57d0e4cb78fc76e0bfc2e6953fa9716b2a5cf2de0117ed8eb5/alembic-1.6.5-py2.py3-none-any.whl (164kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 51.3MB/s \n",
            "\u001b[?25hCollecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/11/aea1cacbd4cf8262809c4d6f95dcb3f2802594de1f51c5bd454d69bf15c5/cliff-3.8.0-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4->lightautoml) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4->lightautoml) (3.0.12)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=4->lightautoml) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 41.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn->lightautoml) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->lightautoml) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<2.0,>=1.0; python_version < \"3.8\"->lightautoml) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->lightautoml) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: pytest in /usr/local/lib/python3.7/dist-packages (from autowoe>=1.2->lightautoml) (3.6.4)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.7/dist-packages (from autowoe>=1.2->lightautoml) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: sphinx in /usr/local/lib/python3.7/dist-packages (from autowoe>=1.2->lightautoml) (1.8.5)\n",
            "Collecting sphinx-rtd-theme\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/24/2475e8f83519b54b2148d4a56eb1111f9cec630d088c3ffc214492c12107/sphinx_rtd_theme-0.5.2-py2.py3-none-any.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2MB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->lightautoml) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->lightautoml) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays->lightautoml) (0.2.1)\n",
            "Requirement already satisfied, skipping upgrade: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays->lightautoml) (2.1.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.7/dist-packages (from holidays->lightautoml) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: convertdate>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from holidays->lightautoml) (2.3.2)\n",
            "Collecting opencv-python-headless>=4.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/84/72ec52fbac4775c2a5bf0ee5573c922a0cac35eb841907edf56493a5e313/opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2MB 68kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->lightautoml) (5.0.0)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->lightautoml) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: plotly in /usr/local/lib/python3.7/dist-packages (from catboost->lightautoml) (4.4.1)\n",
            "Requirement already satisfied, skipping upgrade: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost->lightautoml) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna->lightautoml) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna->lightautoml) (2.4.7)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.3MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/e0/1d4702dd81121d04a477c272d47ee5b6bc970d1a0990b11befa275c55cf2/pbr-5.6.0-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 59.8MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/8b/15061b32332bb35ea2a2f6263d0f616779d576e82739ec8e7fcf3c94abf5/cmd2-1.5.0-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 59.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->lightautoml) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4->lightautoml) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4->lightautoml) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4->lightautoml) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4->lightautoml) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4->lightautoml) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->lightautoml) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->lightautoml) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->autowoe>=1.2->lightautoml) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autowoe>=1.2->lightautoml) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->autowoe>=1.2->lightautoml) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autowoe>=1.2->lightautoml) (8.7.0)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autowoe>=1.2->lightautoml) (21.2.0)\n",
            "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autowoe>=1.2->lightautoml) (1.10.0)\n",
            "Requirement already satisfied, skipping upgrade: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: docutils>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (0.17.1)\n",
            "Requirement already satisfied, skipping upgrade: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (0.7.12)\n",
            "Requirement already satisfied, skipping upgrade: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (1.2.4)\n",
            "Requirement already satisfied, skipping upgrade: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->autowoe>=1.2->lightautoml) (2.9.1)\n",
            "Requirement already satisfied, skipping upgrade: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays->lightautoml) (0.5.11)\n",
            "Requirement already satisfied, skipping upgrade: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost->lightautoml) (1.3.3)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->lightautoml) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/2c/4c64579f847bd5d539803c8b909e54ba087a79d01bb3aba433a95879a6c5/pyperclip-1.8.2.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx->autowoe>=1.2->lightautoml) (1.1.4)\n",
            "Building wheels for collected packages: json2html, log-calls, efficientnet-pytorch, pyperclip\n",
            "  Building wheel for json2html (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for json2html: filename=json2html-1.3.0-cp37-none-any.whl size=7610 sha256=84784934fc0871a0b29e14459f2dc68f1cb6d7a4127038b37ed004ab455da086\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/36/ad/386be30507bcb8f0c9830004bd776132eba63c1b945ed79255\n",
            "  Building wheel for log-calls (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for log-calls: filename=log_calls-0.3.2-cp37-none-any.whl size=51842 sha256=e0d0790fb2fb43a07a6bde938250021474d9aafa90d36d42269ecdb41585992a\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/df/f7/db7e08f521e151e8d9abd7824845480b78a636d95237c601a4\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-cp37-none-any.whl size=16443 sha256=135755aab57ec9d6aacdfd9e2b4bfe84d7515bba5e07b58e0ed7d66c53de8cf4\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/27/aa/c46d23c4e8cc72d41283862b1437e0b3ad318417e8ed7d5921\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-cp37-none-any.whl size=11136 sha256=14b5a219b0c2d992ffe60b63a66de7abc089d7a74eaa01ed56cab2a7936013d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/af/b8/3407109267803f4015e1ee2ff23be0c8c19ce4008665931ee1\n",
            "Successfully built json2html log-calls efficientnet-pytorch pyperclip\n",
            "\u001b[31mERROR: sphinx-rtd-theme 0.5.2 has requirement docutils<0.17, but you'll have docutils 0.17.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: lightgbm, cmaes, colorlog, python-editor, Mako, alembic, importlib-metadata, pbr, stevedore, colorama, pyperclip, cmd2, cliff, optuna, huggingface-hub, sacremoses, tokenizers, transformers, poetry-core, json2html, sphinx-rtd-theme, autowoe, log-calls, opencv-python-headless, albumentations, efficientnet-pytorch, lightautoml\n",
            "  Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Found existing installation: importlib-metadata 4.0.1\n",
            "    Uninstalling importlib-metadata-4.0.1:\n",
            "      Successfully uninstalled importlib-metadata-4.0.1\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed Mako-1.1.4 albumentations-1.0.0 alembic-1.6.5 autowoe-1.2.5 cliff-3.8.0 cmaes-0.8.2 cmd2-1.5.0 colorama-0.4.4 colorlog-5.0.1 efficientnet-pytorch-0.7.1 huggingface-hub-0.0.8 importlib-metadata-1.7.0 json2html-1.3.0 lightautoml-0.2.14 lightgbm-2.3.1 log-calls-0.3.2 opencv-python-headless-4.5.2.52 optuna-2.7.0 pbr-5.6.0 poetry-core-1.0.3 pyperclip-1.8.2 python-editor-1.0.4 sacremoses-0.0.45 sphinx-rtd-theme-0.5.2 stevedore-3.3.0 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl3SF2-sITsF"
      },
      "source": [
        "# 1. Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTKRcmN7H7kk"
      },
      "source": [
        "# Standard python libraries\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "\n",
        "# Installed libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Imports from our package\n",
        "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
        "from lightautoml.tasks import Task"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD1esm7CIVFX"
      },
      "source": [
        "# 2. Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMsTMUMgIajZ"
      },
      "source": [
        "N_THREADS = 256 # threads cnt for lgbm and linear models\n",
        "N_FOLDS = 5 # folds cnt for AutoML\n",
        "RANDOM_STATE = 42 # fixed random state for various reasons\n",
        "TEST_SIZE = 0.2 # Test size for metric check\n",
        "TIMEOUT = 1 * 3600 # Time in seconds for automl run\n",
        "TARGET_NAME = 'target'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfCTk2I4ItTp"
      },
      "source": [
        "# 3. Data load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Vv0TBM6TIeiQ",
        "outputId": "826dc32e-a99b-4dcb-fd0e-58cd64a5b1da"
      },
      "source": [
        "train_data = pd.read_csv('train.csv')\n",
        "train_data[TARGET_NAME] = train_data[TARGET_NAME].str.slice(start=6).astype(int) - 1\n",
        "train_data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>feature_11</th>\n",
              "      <th>feature_12</th>\n",
              "      <th>feature_13</th>\n",
              "      <th>feature_14</th>\n",
              "      <th>feature_15</th>\n",
              "      <th>feature_16</th>\n",
              "      <th>feature_17</th>\n",
              "      <th>feature_18</th>\n",
              "      <th>feature_19</th>\n",
              "      <th>feature_20</th>\n",
              "      <th>feature_21</th>\n",
              "      <th>feature_22</th>\n",
              "      <th>feature_23</th>\n",
              "      <th>feature_24</th>\n",
              "      <th>feature_25</th>\n",
              "      <th>feature_26</th>\n",
              "      <th>feature_27</th>\n",
              "      <th>feature_28</th>\n",
              "      <th>feature_29</th>\n",
              "      <th>feature_30</th>\n",
              "      <th>feature_31</th>\n",
              "      <th>feature_32</th>\n",
              "      <th>feature_33</th>\n",
              "      <th>feature_34</th>\n",
              "      <th>feature_35</th>\n",
              "      <th>feature_36</th>\n",
              "      <th>feature_37</th>\n",
              "      <th>feature_38</th>\n",
              "      <th>feature_39</th>\n",
              "      <th>feature_40</th>\n",
              "      <th>feature_41</th>\n",
              "      <th>feature_42</th>\n",
              "      <th>feature_43</th>\n",
              "      <th>feature_44</th>\n",
              "      <th>feature_45</th>\n",
              "      <th>feature_46</th>\n",
              "      <th>feature_47</th>\n",
              "      <th>feature_48</th>\n",
              "      <th>feature_49</th>\n",
              "      <th>feature_50</th>\n",
              "      <th>feature_51</th>\n",
              "      <th>feature_52</th>\n",
              "      <th>feature_53</th>\n",
              "      <th>feature_54</th>\n",
              "      <th>feature_55</th>\n",
              "      <th>feature_56</th>\n",
              "      <th>feature_57</th>\n",
              "      <th>feature_58</th>\n",
              "      <th>feature_59</th>\n",
              "      <th>feature_60</th>\n",
              "      <th>feature_61</th>\n",
              "      <th>feature_62</th>\n",
              "      <th>feature_63</th>\n",
              "      <th>feature_64</th>\n",
              "      <th>feature_65</th>\n",
              "      <th>feature_66</th>\n",
              "      <th>feature_67</th>\n",
              "      <th>feature_68</th>\n",
              "      <th>feature_69</th>\n",
              "      <th>feature_70</th>\n",
              "      <th>feature_71</th>\n",
              "      <th>feature_72</th>\n",
              "      <th>feature_73</th>\n",
              "      <th>feature_74</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  feature_0  feature_1  ...  feature_73  feature_74  target\n",
              "0   0          0          0  ...           0           0       5\n",
              "1   1          0          0  ...           1           0       5\n",
              "2   2          0          0  ...           0           0       1\n",
              "3   3          0          0  ...           3           0       7\n",
              "4   4          1          0  ...           0           0       1\n",
              "\n",
              "[5 rows x 77 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "srXaMhp3X-YO",
        "outputId": "d8d15e50-2004-440a-f44b-dc3737e6fc1c"
      },
      "source": [
        "test_data = pd.read_csv('test.csv')\n",
        "test_data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>feature_11</th>\n",
              "      <th>feature_12</th>\n",
              "      <th>feature_13</th>\n",
              "      <th>feature_14</th>\n",
              "      <th>feature_15</th>\n",
              "      <th>feature_16</th>\n",
              "      <th>feature_17</th>\n",
              "      <th>feature_18</th>\n",
              "      <th>feature_19</th>\n",
              "      <th>feature_20</th>\n",
              "      <th>feature_21</th>\n",
              "      <th>feature_22</th>\n",
              "      <th>feature_23</th>\n",
              "      <th>feature_24</th>\n",
              "      <th>feature_25</th>\n",
              "      <th>feature_26</th>\n",
              "      <th>feature_27</th>\n",
              "      <th>feature_28</th>\n",
              "      <th>feature_29</th>\n",
              "      <th>feature_30</th>\n",
              "      <th>feature_31</th>\n",
              "      <th>feature_32</th>\n",
              "      <th>feature_33</th>\n",
              "      <th>feature_34</th>\n",
              "      <th>feature_35</th>\n",
              "      <th>feature_36</th>\n",
              "      <th>feature_37</th>\n",
              "      <th>feature_38</th>\n",
              "      <th>feature_39</th>\n",
              "      <th>feature_40</th>\n",
              "      <th>feature_41</th>\n",
              "      <th>feature_42</th>\n",
              "      <th>feature_43</th>\n",
              "      <th>feature_44</th>\n",
              "      <th>feature_45</th>\n",
              "      <th>feature_46</th>\n",
              "      <th>feature_47</th>\n",
              "      <th>feature_48</th>\n",
              "      <th>feature_49</th>\n",
              "      <th>feature_50</th>\n",
              "      <th>feature_51</th>\n",
              "      <th>feature_52</th>\n",
              "      <th>feature_53</th>\n",
              "      <th>feature_54</th>\n",
              "      <th>feature_55</th>\n",
              "      <th>feature_56</th>\n",
              "      <th>feature_57</th>\n",
              "      <th>feature_58</th>\n",
              "      <th>feature_59</th>\n",
              "      <th>feature_60</th>\n",
              "      <th>feature_61</th>\n",
              "      <th>feature_62</th>\n",
              "      <th>feature_63</th>\n",
              "      <th>feature_64</th>\n",
              "      <th>feature_65</th>\n",
              "      <th>feature_66</th>\n",
              "      <th>feature_67</th>\n",
              "      <th>feature_68</th>\n",
              "      <th>feature_69</th>\n",
              "      <th>feature_70</th>\n",
              "      <th>feature_71</th>\n",
              "      <th>feature_72</th>\n",
              "      <th>feature_73</th>\n",
              "      <th>feature_74</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>200001</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>200002</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>200003</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>200004</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  feature_0  feature_1  ...  feature_72  feature_73  feature_74\n",
              "0  200000          0          0  ...           0           0           0\n",
              "1  200001          1          2  ...           3           0           0\n",
              "2  200002          0          1  ...           2           0           0\n",
              "3  200003          0          0  ...           4           0           0\n",
              "4  200004          0          0  ...           0           1           0\n",
              "\n",
              "[5 rows x 76 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "2XJC_1KCIyuV",
        "outputId": "f5ff3dc4-9469-44f7-eeb5-bbbb66ed432a"
      },
      "source": [
        "submission = pd.read_csv('sample_submission.csv')\n",
        "submission.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "      <th>Class_4</th>\n",
              "      <th>Class_5</th>\n",
              "      <th>Class_6</th>\n",
              "      <th>Class_7</th>\n",
              "      <th>Class_8</th>\n",
              "      <th>Class_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200000</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>200001</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>200002</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>200003</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>200004</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  Class_1  Class_2  Class_3  ...  Class_6  Class_7  Class_8  Class_9\n",
              "0  200000   0.1111   0.1111   0.1111  ...   0.1111   0.1111   0.1111   0.1111\n",
              "1  200001   0.1111   0.1111   0.1111  ...   0.1111   0.1111   0.1111   0.1111\n",
              "2  200002   0.1111   0.1111   0.1111  ...   0.1111   0.1111   0.1111   0.1111\n",
              "3  200003   0.1111   0.1111   0.1111  ...   0.1111   0.1111   0.1111   0.1111\n",
              "4  200004   0.1111   0.1111   0.1111  ...   0.1111   0.1111   0.1111   0.1111\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ojnaxx5sJm06"
      },
      "source": [
        "# 4. AutoML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBVoyZPCJ4Vt"
      },
      "source": [
        "## 4.1. Create Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DozGgTA5J8-o",
        "outputId": "844f84f1-91aa-48a1-d807-0023f3e4cf03"
      },
      "source": [
        "%%time\n",
        "\n",
        "task = Task('multiclass',)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.37 ms, sys: 63 µs, total: 6.44 ms\n",
            "Wall time: 9.64 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY9I59ONKDRK"
      },
      "source": [
        "## 4.2. Setup columns roles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm3Fll2AKFfk",
        "outputId": "a6ec0d76-f099-4e1f-8221-73791e6f0a83"
      },
      "source": [
        "%%time\n",
        "\n",
        "roles = {\n",
        "    'target': TARGET_NAME,\n",
        "    'drop': ['id'],\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
            "Wall time: 7.63 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIj8Pq8MKKzp"
      },
      "source": [
        "## 4.3. Train on full data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMDlqOV8JgwP",
        "outputId": "929a8a6e-be76-46ea-a645-8cd88c54eed2"
      },
      "source": [
        "%%time \n",
        "\n",
        "automl = TabularUtilizedAutoML(task = task, \n",
        "                               timeout = TIMEOUT,\n",
        "                               cpu_limit = N_THREADS,\n",
        "                               general_params = {'use_algos': [['lgb', 'cb', 'cb_tuned'], ['linear_l2', 'cb']]},\n",
        "                               reader_params = {'n_jobs': N_THREADS},\n",
        "                               )\n",
        "oof_pred = automl.fit_predict(train_data, roles = roles)\n",
        "print('oof_pred:\\n{}\\nShape = {}'.format(oof_pred[:10], oof_pred.shape))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current random state: {'reader_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n",
            "Found reader_params in kwargs, need to combine\n",
            "Merged variant for reader_params = {'n_jobs': 256, 'random_state': 42}\n",
            "Found general_params in kwargs, need to combine\n",
            "Merged variant for general_params = {'use_algos': [['lgb', 'cb', 'cb_tuned'], ['linear_l2', 'cb']], 'return_all_predictions': False}\n",
            "Start automl preset with listed constraints:\n",
            "- time: 3599.9851536750793 seconds\n",
            "- cpus: 256 cores\n",
            "- memory: 16 gb\n",
            "\n",
            "Train data shape: (200000, 77)\n",
            "Feats was rejected during automatic roles guess: []\n",
            "\n",
            "\n",
            "Layer 1 ...\n",
            "Train process start. Time left 3548.8636877536774 secs\n",
            "Start fitting Lvl_0_Pipe_0_Mod_0_LightGBM ...\n",
            "\n",
            "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_0_LightGBM =====\n",
            "\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid's multi_logloss: 1.75893\n",
            "[200]\tvalid's multi_logloss: 1.75424\n",
            "[300]\tvalid's multi_logloss: 1.7555\n",
            "Early stopping, best iteration is:\n",
            "[214]\tvalid's multi_logloss: 1.75412\n",
            "\n",
            "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_0_LightGBM =====\n",
            "\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid's multi_logloss: 1.7528\n",
            "[200]\tvalid's multi_logloss: 1.74732\n",
            "[300]\tvalid's multi_logloss: 1.74817\n",
            "Early stopping, best iteration is:\n",
            "[231]\tvalid's multi_logloss: 1.74723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Time limit exceeded after calculating fold 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Lvl_0_Pipe_0_Mod_0_LightGBM fitting and predicting completed\n",
            "Start fitting Lvl_0_Pipe_0_Mod_1_CatBoost ...\n",
            "\n",
            "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_1_CatBoost =====\n",
            "\n",
            "0:\tlearn: 2.1728049\ttest: 2.1730550\tbest: 2.1730550 (0)\ttotal: 412ms\tremaining: 27m 27s\n",
            "100:\tlearn: 1.7608880\ttest: 1.7687804\tbest: 1.7687804 (100)\ttotal: 36s\tremaining: 23m 10s\n",
            "200:\tlearn: 1.7444941\ttest: 1.7577653\tbest: 1.7577653 (200)\ttotal: 1m 7s\tremaining: 21m 12s\n",
            "300:\tlearn: 1.7369694\ttest: 1.7553245\tbest: 1.7553245 (300)\ttotal: 1m 35s\tremaining: 19m 33s\n",
            "400:\tlearn: 1.7308842\ttest: 1.7540464\tbest: 1.7540464 (400)\ttotal: 2m 2s\tremaining: 18m 20s\n",
            "500:\tlearn: 1.7244361\ttest: 1.7528771\tbest: 1.7528771 (500)\ttotal: 2m 31s\tremaining: 17m 37s\n",
            "600:\tlearn: 1.7185919\ttest: 1.7523251\tbest: 1.7523251 (600)\ttotal: 2m 58s\tremaining: 16m 47s\n",
            "700:\tlearn: 1.7131240\ttest: 1.7520251\tbest: 1.7520106 (699)\ttotal: 3m 24s\tremaining: 16m\n",
            "800:\tlearn: 1.7080102\ttest: 1.7518689\tbest: 1.7518462 (797)\ttotal: 3m 50s\tremaining: 15m 19s\n",
            "900:\tlearn: 1.7031889\ttest: 1.7517333\tbest: 1.7516807 (870)\ttotal: 4m 15s\tremaining: 14m 39s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 1.751680655\n",
            "bestIteration = 870\n",
            "\n",
            "Shrink model to first 871 iterations.\n",
            "\n",
            "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_1_CatBoost =====\n",
            "\n",
            "0:\tlearn: 2.1729079\ttest: 2.1729186\tbest: 2.1729186 (0)\ttotal: 357ms\tremaining: 23m 49s\n",
            "100:\tlearn: 1.7626253\ttest: 1.7642509\tbest: 1.7642509 (100)\ttotal: 35.6s\tremaining: 22m 52s\n",
            "200:\tlearn: 1.7466155\ttest: 1.7519607\tbest: 1.7519607 (200)\ttotal: 1m 6s\tremaining: 20m 58s\n",
            "300:\tlearn: 1.7389887\ttest: 1.7488480\tbest: 1.7488480 (300)\ttotal: 1m 34s\tremaining: 19m 23s\n",
            "400:\tlearn: 1.7328223\ttest: 1.7472193\tbest: 1.7472193 (400)\ttotal: 2m 2s\tremaining: 18m 15s\n",
            "500:\tlearn: 1.7263358\ttest: 1.7457997\tbest: 1.7457997 (500)\ttotal: 2m 30s\tremaining: 17m 33s\n",
            "600:\tlearn: 1.7205373\ttest: 1.7450298\tbest: 1.7450287 (599)\ttotal: 2m 57s\tremaining: 16m 45s\n",
            "700:\tlearn: 1.7153071\ttest: 1.7446290\tbest: 1.7446200 (698)\ttotal: 3m 24s\tremaining: 16m\n",
            "800:\tlearn: 1.7102769\ttest: 1.7443196\tbest: 1.7443150 (795)\ttotal: 3m 49s\tremaining: 15m 16s\n",
            "900:\tlearn: 1.7054060\ttest: 1.7441670\tbest: 1.7441670 (900)\ttotal: 4m 15s\tremaining: 14m 37s\n",
            "1000:\tlearn: 1.7007491\ttest: 1.7440766\tbest: 1.7440392 (969)\ttotal: 4m 40s\tremaining: 14m 1s\n",
            "1100:\tlearn: 1.6963041\ttest: 1.7440517\tbest: 1.7439853 (1045)\ttotal: 5m 6s\tremaining: 13m 26s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 1.74398531\n",
            "bestIteration = 1045\n",
            "\n",
            "Shrink model to first 1046 iterations.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Time limit exceeded after calculating fold 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Lvl_0_Pipe_0_Mod_1_CatBoost fitting and predicting completed\n",
            "Optuna may run 1 secs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Start fitting Lvl_0_Pipe_0_Mod_2_CatBoost ...\n",
            "\n",
            "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_2_CatBoost =====\n",
            "\n",
            "0:\tlearn: 2.1729409\ttest: 2.1731485\tbest: 2.1731485 (0)\ttotal: 320ms\tremaining: 21m 18s\n",
            "100:\tlearn: 1.7669339\ttest: 1.7726229\tbest: 1.7726229 (100)\ttotal: 31.2s\tremaining: 20m 5s\n",
            "200:\tlearn: 1.7511661\ttest: 1.7597123\tbest: 1.7597123 (200)\ttotal: 1m\tremaining: 18m 54s\n",
            "300:\tlearn: 1.7457115\ttest: 1.7565433\tbest: 1.7565433 (300)\ttotal: 1m 26s\tremaining: 17m 46s\n",
            "400:\tlearn: 1.7420037\ttest: 1.7548603\tbest: 1.7548603 (400)\ttotal: 1m 52s\tremaining: 16m 46s\n",
            "500:\tlearn: 1.7382577\ttest: 1.7536908\tbest: 1.7536908 (500)\ttotal: 2m 19s\tremaining: 16m 12s\n",
            "600:\tlearn: 1.7352083\ttest: 1.7530468\tbest: 1.7530455 (598)\ttotal: 2m 44s\tremaining: 15m 28s\n",
            "700:\tlearn: 1.7325366\ttest: 1.7525887\tbest: 1.7525887 (700)\ttotal: 3m 8s\tremaining: 14m 46s\n",
            "800:\tlearn: 1.7301623\ttest: 1.7522229\tbest: 1.7522229 (800)\ttotal: 3m 32s\tremaining: 14m 7s\n",
            "900:\tlearn: 1.7279965\ttest: 1.7520129\tbest: 1.7520129 (900)\ttotal: 3m 55s\tremaining: 13m 30s\n",
            "1000:\tlearn: 1.7260120\ttest: 1.7518524\tbest: 1.7518524 (1000)\ttotal: 4m 18s\tremaining: 12m 55s\n",
            "1100:\tlearn: 1.7241203\ttest: 1.7517401\tbest: 1.7517296 (1090)\ttotal: 4m 42s\tremaining: 12m 23s\n",
            "1200:\tlearn: 1.7222586\ttest: 1.7516703\tbest: 1.7516600 (1173)\ttotal: 5m 6s\tremaining: 11m 53s\n",
            "1300:\tlearn: 1.7204231\ttest: 1.7516129\tbest: 1.7515900 (1289)\ttotal: 5m 29s\tremaining: 11m 23s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 1.751589955\n",
            "bestIteration = 1289\n",
            "\n",
            "Shrink model to first 1290 iterations.\n",
            "Lvl_0_Pipe_0_Mod_2_CatBoost fitting and predicting completed\n",
            "Start fitting Lvl_0_Pipe_0_Mod_2_CatBoost ...\n",
            "\n",
            "===== Start working with fold 0 for Lvl_0_Pipe_0_Mod_2_CatBoost =====\n",
            "\n",
            "0:\tlearn: 2.1729409\ttest: 2.1731485\tbest: 2.1731485 (0)\ttotal: 311ms\tremaining: 15m 33s\n",
            "100:\tlearn: 1.7669339\ttest: 1.7726229\tbest: 1.7726229 (100)\ttotal: 31.1s\tremaining: 14m 53s\n",
            "200:\tlearn: 1.7511661\ttest: 1.7597123\tbest: 1.7597123 (200)\ttotal: 1m\tremaining: 13m 56s\n",
            "300:\tlearn: 1.7457115\ttest: 1.7565433\tbest: 1.7565433 (300)\ttotal: 1m 26s\tremaining: 12m 56s\n",
            "400:\tlearn: 1.7420037\ttest: 1.7548603\tbest: 1.7548603 (400)\ttotal: 1m 52s\tremaining: 12m 7s\n",
            "500:\tlearn: 1.7382577\ttest: 1.7536908\tbest: 1.7536908 (500)\ttotal: 2m 19s\tremaining: 11m 34s\n",
            "600:\tlearn: 1.7352083\ttest: 1.7530468\tbest: 1.7530455 (598)\ttotal: 2m 44s\tremaining: 10m 54s\n",
            "700:\tlearn: 1.7325366\ttest: 1.7525887\tbest: 1.7525887 (700)\ttotal: 3m 8s\tremaining: 10m 17s\n",
            "800:\tlearn: 1.7301623\ttest: 1.7522229\tbest: 1.7522229 (800)\ttotal: 3m 32s\tremaining: 9m 42s\n",
            "900:\tlearn: 1.7279965\ttest: 1.7520129\tbest: 1.7520129 (900)\ttotal: 3m 55s\tremaining: 9m 8s\n",
            "1000:\tlearn: 1.7260120\ttest: 1.7518524\tbest: 1.7518524 (1000)\ttotal: 4m 18s\tremaining: 8m 36s\n",
            "1100:\tlearn: 1.7241203\ttest: 1.7517401\tbest: 1.7517296 (1090)\ttotal: 4m 42s\tremaining: 8m 6s\n",
            "1200:\tlearn: 1.7222586\ttest: 1.7516703\tbest: 1.7516600 (1173)\ttotal: 5m 5s\tremaining: 7m 37s\n",
            "1300:\tlearn: 1.7204231\ttest: 1.7516129\tbest: 1.7515900 (1289)\ttotal: 5m 28s\tremaining: 7m 8s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 1.751589955\n",
            "bestIteration = 1289\n",
            "\n",
            "Shrink model to first 1290 iterations.\n",
            "\n",
            "===== Start working with fold 1 for Lvl_0_Pipe_0_Mod_2_CatBoost =====\n",
            "\n",
            "0:\tlearn: 2.1730282\ttest: 2.1730349\tbest: 2.1730349 (0)\ttotal: 329ms\tremaining: 16m 25s\n",
            "100:\tlearn: 1.7684135\ttest: 1.7679936\tbest: 1.7679936 (100)\ttotal: 31.8s\tremaining: 15m 12s\n",
            "200:\tlearn: 1.7530953\ttest: 1.7538148\tbest: 1.7538148 (200)\ttotal: 1m\tremaining: 14m 8s\n",
            "300:\tlearn: 1.7475915\ttest: 1.7499971\tbest: 1.7499971 (300)\ttotal: 1m 28s\tremaining: 13m 9s\n",
            "400:\tlearn: 1.7438629\ttest: 1.7480739\tbest: 1.7480739 (400)\ttotal: 1m 53s\tremaining: 12m 18s\n",
            "500:\tlearn: 1.7401143\ttest: 1.7465658\tbest: 1.7465658 (500)\ttotal: 2m 20s\tremaining: 11m 42s\n",
            "600:\tlearn: 1.7371252\ttest: 1.7457303\tbest: 1.7457301 (599)\ttotal: 2m 45s\tremaining: 11m\n",
            "700:\tlearn: 1.7345141\ttest: 1.7452095\tbest: 1.7452079 (699)\ttotal: 3m 10s\tremaining: 10m 23s\n",
            "800:\tlearn: 1.7322255\ttest: 1.7448353\tbest: 1.7448353 (800)\ttotal: 3m 33s\tremaining: 9m 46s\n",
            "900:\tlearn: 1.7300626\ttest: 1.7446531\tbest: 1.7446513 (893)\ttotal: 3m 56s\tremaining: 9m 12s\n",
            "1000:\tlearn: 1.7280619\ttest: 1.7445284\tbest: 1.7445244 (994)\ttotal: 4m 20s\tremaining: 8m 39s\n",
            "1100:\tlearn: 1.7261370\ttest: 1.7444020\tbest: 1.7444009 (1085)\ttotal: 4m 43s\tremaining: 8m 8s\n",
            "1200:\tlearn: 1.7243125\ttest: 1.7443042\tbest: 1.7442892 (1188)\ttotal: 5m 6s\tremaining: 7m 38s\n",
            "1300:\tlearn: 1.7225426\ttest: 1.7442506\tbest: 1.7442340 (1261)\ttotal: 5m 28s\tremaining: 7m 9s\n",
            "1400:\tlearn: 1.7208239\ttest: 1.7441726\tbest: 1.7441697 (1391)\ttotal: 5m 51s\tremaining: 6m 41s\n",
            "1500:\tlearn: 1.7191335\ttest: 1.7441646\tbest: 1.7441611 (1498)\ttotal: 6m 13s\tremaining: 6m 13s\n",
            "1600:\tlearn: 1.7174459\ttest: 1.7441672\tbest: 1.7441358 (1541)\ttotal: 6m 35s\tremaining: 5m 45s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 1.744135754\n",
            "bestIteration = 1541\n",
            "\n",
            "Shrink model to first 1542 iterations.\n",
            "\n",
            "===== Start working with fold 2 for Lvl_0_Pipe_0_Mod_2_CatBoost =====\n",
            "\n",
            "0:\tlearn: 2.1730779\ttest: 2.1729579\tbest: 2.1729579 (0)\ttotal: 326ms\tremaining: 16m 18s\n",
            "100:\tlearn: 1.7680748\ttest: 1.7693226\tbest: 1.7693226 (100)\ttotal: 31.3s\tremaining: 14m 59s\n",
            "200:\tlearn: 1.7524043\ttest: 1.7554682\tbest: 1.7554682 (200)\ttotal: 1m\tremaining: 13m 56s\n",
            "300:\tlearn: 1.7471198\ttest: 1.7521188\tbest: 1.7521188 (300)\ttotal: 1m 26s\tremaining: 12m 56s\n",
            "400:\tlearn: 1.7433835\ttest: 1.7502459\tbest: 1.7502459 (400)\ttotal: 1m 52s\tremaining: 12m 9s\n",
            "500:\tlearn: 1.7395657\ttest: 1.7486997\tbest: 1.7486997 (500)\ttotal: 2m 19s\tremaining: 11m 34s\n",
            "600:\tlearn: 1.7365648\ttest: 1.7479365\tbest: 1.7479365 (600)\ttotal: 2m 43s\tremaining: 10m 54s\n",
            "700:\tlearn: 1.7338348\ttest: 1.7473715\tbest: 1.7473715 (700)\ttotal: 3m 8s\tremaining: 10m 17s\n",
            "800:\tlearn: 1.7315140\ttest: 1.7470652\tbest: 1.7470641 (798)\ttotal: 3m 31s\tremaining: 9m 41s\n",
            "900:\tlearn: 1.7293490\ttest: 1.7468550\tbest: 1.7468550 (900)\ttotal: 3m 55s\tremaining: 9m 8s\n",
            "1000:\tlearn: 1.7272562\ttest: 1.7466879\tbest: 1.7466879 (1000)\ttotal: 4m 19s\tremaining: 8m 38s\n",
            "1100:\tlearn: 1.7253593\ttest: 1.7465366\tbest: 1.7465355 (1099)\ttotal: 4m 42s\tremaining: 8m 7s\n",
            "1200:\tlearn: 1.7235534\ttest: 1.7464165\tbest: 1.7464165 (1200)\ttotal: 5m 6s\tremaining: 7m 38s\n",
            "1300:\tlearn: 1.7217940\ttest: 1.7464217\tbest: 1.7464029 (1269)\ttotal: 5m 29s\tremaining: 7m 9s\n",
            "1400:\tlearn: 1.7200493\ttest: 1.7464390\tbest: 1.7463951 (1334)\ttotal: 5m 52s\tremaining: 6m 42s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 1.746395107\n",
            "bestIteration = 1334\n",
            "\n",
            "Shrink model to first 1335 iterations.\n",
            "\n",
            "===== Start working with fold 3 for Lvl_0_Pipe_0_Mod_2_CatBoost =====\n",
            "\n",
            "0:\tlearn: 2.1730595\ttest: 2.1729284\tbest: 2.1729284 (0)\ttotal: 342ms\tremaining: 17m 5s\n",
            "100:\tlearn: 1.7677756\ttest: 1.7697953\tbest: 1.7697953 (100)\ttotal: 31.8s\tremaining: 15m 12s\n",
            "200:\tlearn: 1.7517656\ttest: 1.7566480\tbest: 1.7566480 (200)\ttotal: 1m\tremaining: 14m 7s\n",
            "300:\tlearn: 1.7463997\ttest: 1.7533905\tbest: 1.7533905 (300)\ttotal: 1m 27s\tremaining: 13m 5s\n",
            "400:\tlearn: 1.7426936\ttest: 1.7517296\tbest: 1.7517296 (400)\ttotal: 1m 53s\tremaining: 12m 14s\n",
            "500:\tlearn: 1.7390740\ttest: 1.7504878\tbest: 1.7504878 (500)\ttotal: 2m 19s\tremaining: 11m 35s\n",
            "600:\tlearn: 1.7360460\ttest: 1.7496845\tbest: 1.7496845 (600)\ttotal: 2m 44s\tremaining: 10m 56s\n",
            "700:\tlearn: 1.7333995\ttest: 1.7491602\tbest: 1.7491602 (700)\ttotal: 3m 9s\tremaining: 10m 20s\n",
            "800:\tlearn: 1.7311379\ttest: 1.7488060\tbest: 1.7488060 (800)\ttotal: 3m 32s\tremaining: 9m 43s\n",
            "900:\tlearn: 1.7290368\ttest: 1.7486967\tbest: 1.7486923 (898)\ttotal: 3m 55s\tremaining: 9m 9s\n",
            "1000:\tlearn: 1.7270229\ttest: 1.7485332\tbest: 1.7485300 (999)\ttotal: 4m 19s\tremaining: 8m 37s\n",
            "1100:\tlearn: 1.7251028\ttest: 1.7484395\tbest: 1.7484377 (1099)\ttotal: 4m 42s\tremaining: 8m 6s\n",
            "1200:\tlearn: 1.7231678\ttest: 1.7483660\tbest: 1.7483660 (1200)\ttotal: 5m 5s\tremaining: 7m 36s\n",
            "1300:\tlearn: 1.7213887\ttest: 1.7482745\tbest: 1.7482745 (1300)\ttotal: 5m 27s\tremaining: 7m 8s\n",
            "1400:\tlearn: 1.7196293\ttest: 1.7481855\tbest: 1.7481724 (1390)\ttotal: 5m 50s\tremaining: 6m 40s\n",
            "1500:\tlearn: 1.7178821\ttest: 1.7481626\tbest: 1.7481600 (1499)\ttotal: 6m 13s\tremaining: 6m 12s\n",
            "1600:\tlearn: 1.7162614\ttest: 1.7481588\tbest: 1.7481492 (1567)\ttotal: 6m 36s\tremaining: 5m 46s\n",
            "1700:\tlearn: 1.7146903\ttest: 1.7481763\tbest: 1.7481487 (1607)\ttotal: 6m 58s\tremaining: 5m 19s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 1.748148708\n",
            "bestIteration = 1607\n",
            "\n",
            "Shrink model to first 1608 iterations.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Time limit exceeded after calculating fold 3\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Lvl_0_Pipe_0_Mod_2_CatBoost fitting and predicting completed\n",
            "Time left 682.637748003006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Time limit exceeded in one of the tasks. AutoML will blend level 1 models.                                         \n",
            "Try to set higher time limits or use Profiler to find bottleneck and optimize Pipelines settings\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Blending: Optimization starts with equal weights and score -1.7470666382503928\n",
            "Blending, iter 0: score = -1.74706256334919, weights = [0.30171794 0.35706687 0.3412152 ]\n",
            "Blending, iter 1: score = -1.7470625537043438, weights = [0.30116066 0.35948393 0.33935544]\n",
            "Blending, iter 2: score = -1.7470625537043438, weights = [0.30116066 0.35948393 0.33935544]\n",
            "No score update. Terminated\n",
            "\n",
            "Automl preset training completed in 2923.35 seconds.\n",
            "oof_pred:\n",
            "array([[0.01812763, 0.01758972, 0.01590177, 0.00772718, 0.00409396,\n",
            "        0.7589494 , 0.02983649, 0.10947287, 0.03830104],\n",
            "       [0.03740199, 0.13258949, 0.07632411, 0.02374497, 0.00937621,\n",
            "        0.46721923, 0.03390833, 0.11283244, 0.10660326],\n",
            "       [0.05183011, 0.11258177, 0.08019474, 0.02383038, 0.01906432,\n",
            "        0.15213107, 0.09430991, 0.28979713, 0.17626062],\n",
            "       [0.05311953, 0.10709359, 0.10309666, 0.02954577, 0.03115356,\n",
            "        0.10480604, 0.09692325, 0.29662645, 0.1776352 ],\n",
            "       [0.060084  , 0.3083984 , 0.14751643, 0.0266003 , 0.01523347,\n",
            "        0.13615562, 0.0387946 , 0.11100428, 0.15621293],\n",
            "       [0.05393246, 0.2246397 , 0.10566752, 0.03338166, 0.0152467 ,\n",
            "        0.07859436, 0.07399236, 0.24620043, 0.16834483],\n",
            "       [0.03999007, 0.07261433, 0.05722073, 0.02576291, 0.01509434,\n",
            "        0.27452624, 0.09140752, 0.26990402, 0.15347983],\n",
            "       [0.0542878 , 0.04695052, 0.03214573, 0.02548541, 0.02014237,\n",
            "        0.27083334, 0.11646757, 0.32283717, 0.11085016],\n",
            "       [0.05574438, 0.1515202 , 0.11011797, 0.03962411, 0.02123816,\n",
            "        0.05628906, 0.10100447, 0.27807862, 0.18638305],\n",
            "       [0.05130249, 0.25361055, 0.16348375, 0.02732548, 0.01573582,\n",
            "        0.08008543, 0.06278897, 0.17361379, 0.17205371]], dtype=float32)\n",
            "Shape = (200000, 9)\n",
            "CPU times: user 1h 33min 28s, sys: 17.9 s, total: 1h 33min 46s\n",
            "Wall time: 48min 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3zmTdDTKu2v"
      },
      "source": [
        "## 4.4. Predict for test data and check OOF score¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "xscutZFYKXe7",
        "outputId": "d425466b-9815-4037-e9e2-49747d313501"
      },
      "source": [
        "%%time\n",
        "\n",
        "test_pred = automl.predict(test_data)\n",
        "print('Prediction for test data:\\n{}\\nShape = {}'.format(test_pred[:10], test_pred.shape))\n",
        "\n",
        "print('Check scores...')\n",
        "print('OOF score: {}'.format(log_loss(train_data[TARGET_NAME].values, oof_pred.data)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction for test data:\n",
            "array([[0.05348641, 0.3672707 , 0.15677106, 0.02638205, 0.01312626,\n",
            "        0.17018145, 0.02689078, 0.06281381, 0.12307748],\n",
            "       [0.04164853, 0.08106397, 0.06216176, 0.01925035, 0.01376328,\n",
            "        0.25311622, 0.07967722, 0.31903496, 0.13028376],\n",
            "       [0.02117894, 0.02978867, 0.02309041, 0.01007608, 0.00621405,\n",
            "        0.68225205, 0.03365135, 0.13306244, 0.06068605],\n",
            "       [0.04800578, 0.118524  , 0.08143333, 0.04029392, 0.01779301,\n",
            "        0.22230107, 0.07258399, 0.23729566, 0.16176929],\n",
            "       [0.04223086, 0.11607187, 0.08137749, 0.02800404, 0.01443975,\n",
            "        0.2972453 , 0.06323846, 0.21323314, 0.14415911],\n",
            "       [0.0527746 , 0.20720667, 0.10607398, 0.03051032, 0.01192024,\n",
            "        0.27228388, 0.04556207, 0.13641807, 0.13725021],\n",
            "       [0.03755406, 0.11369773, 0.08230691, 0.03093368, 0.01827616,\n",
            "        0.20262474, 0.08814791, 0.26282343, 0.16363543],\n",
            "       [0.04694959, 0.4054562 , 0.16104674, 0.02763849, 0.0169553 ,\n",
            "        0.05356741, 0.0409603 , 0.10256168, 0.14486434],\n",
            "       [0.03427096, 0.05003375, 0.04454625, 0.01643229, 0.01480805,\n",
            "        0.36820617, 0.08946797, 0.2716921 , 0.11054249],\n",
            "       [0.06010552, 0.03649084, 0.02954484, 0.02157361, 0.02450363,\n",
            "        0.2096151 , 0.11401261, 0.39229333, 0.11186052]], dtype=float32)\n",
            "Shape = (100000, 9)\n",
            "Check scores...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-a1df26634149>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\ntest_pred = automl.predict(test_data)\\nprint('Prediction for test data:\\\\n{}\\\\nShape = {}'.format(test_pred[:10], test_pred.shape))\\n\\nprint('Check scores...')\\nprint('OOF score: {}'.format(log_loss(train_data[TARGET_NAME].values, oof_pred.data)))\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2239\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mlogarithm\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnatural\u001b[0m \u001b[0mlogarithm\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m     \"\"\"\n\u001b[0;32m-> 2241\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2242\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX_lJ1moLBFQ"
      },
      "source": [
        "## 4.5. Prepare submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDL_MJdrLDIU"
      },
      "source": [
        "submission.iloc[:, 1:] = test_pred.data\n",
        "submission.to_csv('KTJune_lightautoml_2lvl_1hour.csv', index = False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch0eRmngZvXm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}