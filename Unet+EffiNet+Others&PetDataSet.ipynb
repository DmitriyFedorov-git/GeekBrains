{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Unet+EffiNet+Others&PetDataSet.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mz9VxqhIvvEW",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MQmKthrSBCld",
        "colab": {}
      },
      "source": [
        "!pip install git+https://github.com/tensorflow/examples.git\n",
        "!pip install -U tfds-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YQX7R4bhZy5h",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g87--n2AtyO_",
        "colab": {}
      },
      "source": [
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oWe0_rQM4JbC"
      },
      "source": [
        "## Загрузка датасета Oxford-IIIT Pets\n",
        "\n",
        "Датасет является стандартным датасетом для TensorFlow, однако как упомяналось выше возможно необходимо будет установить модуль tensorflow-datasets для python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "40ITeStwDwZb",
        "colab": {}
      },
      "source": [
        "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rJcVdj_U4vzf"
      },
      "source": [
        "Следующий код выполнит простую аугументацию данных посредством переворота изображений. В дополнение изображение будет нормализовано к 0 и 1. Пиксели сегментационной маски будут помечены {1, 2, 3}, но для удобства из данного цифрового ряда будет вычтено по 1 и в итоге получиться {0, 1, 2}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FD60EbcAQqov",
        "colab": {}
      },
      "source": [
        "def normalize(input_image, input_mask):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  input_mask -= 1\n",
        "  return input_image, input_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2NPlCnBXQwb1",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def load_image_train(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
        "\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zf0S67hJRp3D",
        "colab": {}
      },
      "source": [
        "def load_image_test(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "65-qHTjX5VZh"
      },
      "source": [
        "Датасет уже содержит необходимые тестовый и тренеровочный сплиты, поэтому давайте использовать их."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yHwj2-8SaQli",
        "colab": {}
      },
      "source": [
        "TRAIN_LENGTH = info.splits['train'].num_examples\n",
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 1000\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "39fYScNz9lmo",
        "colab": {}
      },
      "source": [
        "train = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "test = dataset['test'].map(load_image_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DeFwFDN6EVoI",
        "colab": {}
      },
      "source": [
        "train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xa3gMAE_9qNa"
      },
      "source": [
        "Давайте посмотрим на пример  изображения из датасета и соотвествующую ему маску из датасета."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3N2RPAAW9q4W",
        "colab": {}
      },
      "source": [
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a6u_Rblkteqb",
        "colab": {}
      },
      "source": [
        "for image, mask in train.take(1):\n",
        "  sample_image, sample_mask = image, mask\n",
        "display([sample_image, sample_mask])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLxKIOjyVTMH",
        "colab_type": "text"
      },
      "source": [
        "## Определение модели (encoder VGG16)\n",
        "\n",
        "Будем использовать модифицированный U-Net. В качестве энкодера будет использоваться предтренированный VGG16.\n",
        "Декодером будет апсемпл блок уже имплементированный в TensorFlow examples [Pix2pix tutorial](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gnQmoLuPBLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ОСНОВНЫЕ НАБЛЮДЕНИЯ \n",
        "# Пример из keras tutorials segmentation очень долго тренируется (видимо потому что encoder не предобучен)\n",
        "# надо его точность еще раз проверить\n",
        "\n",
        "# ternausnet с ResNet152V2 энкодером за 20 эпох до 0.88. Такой же результат в домашке, где энкодер - VGG16\n",
        "# учится быстрее, чем пример из keras\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlHiZ2uJLfyg",
        "colab_type": "text"
      },
      "source": [
        "# Тип 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo17MZyRJKxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = tf.keras.applications.ResNet152V2(include_top=False, weights='imagenet', input_shape=[128, 128, 3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO6jVNeGJOT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzMtP_LxV8fI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Как ternausnet но с ResNet152V2 энкодером (сам писал)\n",
        "\n",
        "layer_names = [\n",
        "    'input_10',   # 128x128 3\n",
        "    'conv1_conv',   # 64x64 64\n",
        "    'conv2_block3_1_conv',   # 32x32 64\n",
        "    'conv3_block8_1_conv',   # 16x16 128\n",
        "    'conv4_block36_1_conv',  # 8x8 256\n",
        "    'post_relu', #  4x4 2048\n",
        "\n",
        "]\n",
        "layers = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "\n",
        "down_stack.trainable = False\n",
        "\n",
        "up_stack = [\n",
        "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
        "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
        "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
        "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
        "    pix2pix.upsample(32, 3),   # 64x64 -> 128x128\n",
        "]\n",
        "\n",
        "def unet_model(output_channels):\n",
        "  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
        "  x = inputs\n",
        "  skips = down_stack(x)\n",
        "  x = tf.keras.layers.Conv2D(1024, 3, strides=(1, 1), padding='same', activation='relu')(skips[5])\n",
        "  #x = tf.keras.layers.BatchNormalization(x)\n",
        "\n",
        "  x = up_stack[0](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[4]])\n",
        "  x = tf.keras.layers.Conv2D(512, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  x = tf.keras.layers.Conv2D(512, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  #x = tf.keras.layers.BatchNormalization(x)\n",
        "\n",
        "  x = up_stack[1](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[3]])\n",
        "  x = tf.keras.layers.Conv2D(256, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  x = tf.keras.layers.Conv2D(256, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  #x = tf.keras.layers.BatchNormalization(x)\n",
        "\n",
        "  x = up_stack[2](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[2]])\n",
        "  x = tf.keras.layers.Conv2D(128, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  x = tf.keras.layers.Conv2D(128, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  #x = tf.keras.layers.BatchNormalization(x)\n",
        "\n",
        "  x = up_stack[3](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[1]])\n",
        "  x = tf.keras.layers.Conv2D(64, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  x = tf.keras.layers.Conv2D(64, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  #x = tf.keras.layers.BatchNormalization(x)\n",
        "\n",
        "  x = up_stack[4](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[0]])\n",
        "  #x = tf.keras.layers.Conv2D(3, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  x = tf.keras.layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "\n",
        "  #x = tf.keras.layers.Conv2DTranspose(output_channels, 3, strides=2, padding='same')(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAQkpIxFJ33n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_CHANNELS = 3\n",
        "model = unet_model(OUTPUT_CHANNELS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXt1Eu3ZLoaf",
        "colab_type": "text"
      },
      "source": [
        "# Тип 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFMyUzuBj2h1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Пример из keras tutorials segmentation\n",
        "\n",
        "def get_model(img_size, num_classes):\n",
        "    inputs = tf.keras.Input(shape=img_size + (3,))\n",
        "\n",
        "    ### [First half of the network: downsampling inputs] ###\n",
        "\n",
        "    # Entry block\n",
        "    x = tf.keras.layers.Conv2D(32, 3, strides=2, padding=\"same\")(inputs)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
        "    for filters in [64, 128, 256]:\n",
        "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "        x = tf.keras.layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "        x = tf.keras.layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "        x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = tf.keras.layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = tf.keras.layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    ### [Second half of the network: upsampling inputs] ###\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for filters in [256, 128, 64, 32]:\n",
        "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "        x = tf.keras.layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "        x = tf.keras.layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "        x = tf.keras.layers.UpSampling2D(2)(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = tf.keras.layers.UpSampling2D(2)(previous_block_activation)\n",
        "        residual = tf.keras.layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
        "        x = tf.keras.layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    # Add a per-pixel classification layer\n",
        "    outputs = tf.keras.layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
        "    #outputs = layers.Conv2D(3, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "    # Define the model\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq0sLUUCkLdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_size = (128, 128)\n",
        "num_classes = 3\n",
        "model = get_model(img_size, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K6gawjsLsDv",
        "colab_type": "text"
      },
      "source": [
        "# Тип 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjSS8We_i10h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# энкодер из tensorflow tutorials segmentation (mobile v2). с декодером экспериментировал, но результат \n",
        "# не особо изменился. Декодер такой же, но расписан не циклом как в туториале. Самый быстрый вариант\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19ST0927i3mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei2g6vQgLuyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the activations of these layers\n",
        "layer_names = [\n",
        "    'input_1',              # 128x128 3 (не используется, так как прироста точности не дает)\n",
        "    'block_1_expand_relu',   # 64x64 96\n",
        "    'block_3_expand_relu',   # 32x32 144\n",
        "    'block_6_expand_relu',   # 16x16 192\n",
        "    'block_13_expand_relu',  # 8x8 576\n",
        "    'block_16_project',      # 4x4 320\n",
        "]\n",
        "layers = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "\n",
        "down_stack.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJWie2CiiFWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaZ3oHdkS6yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "up_stack = [\n",
        "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
        "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
        "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
        "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSH_tnpGRs0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# взял код из tensorflow tutorials segmentation (mobile v2) и развернул для наглядности\n",
        "# добавление одного сверточного слоя после конкатенации незначительно повысило точность (обучение замедлилось)\n",
        "# добавление второго сверточного слоя после конкатенации значительно замедлило обучение\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "def unet_model(output_channels):\n",
        "  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
        "  x = inputs\n",
        "\n",
        "  # Downsampling through the model\n",
        "  skips = down_stack(x)\n",
        "  x = skips[-1]\n",
        "  #skips = reversed(skips[:-1])\n",
        "\n",
        "  x = up_stack[0](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[4]])\n",
        "  #x = tf.keras.layers.Conv2D(760, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  #x = tf.keras.layers.Conv2D(512, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "  x = up_stack[1](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[3]])\n",
        "  #x = tf.keras.layers.Conv2D(350, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  #x = tf.keras.layers.Conv2D(256, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "  x = up_stack[2](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[2]])\n",
        "  #x = tf.keras.layers.Conv2D(200, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  #x = tf.keras.layers.Conv2D(128, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "  x = up_stack[3](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[1]])\n",
        "  #x = tf.keras.layers.Conv2D(100, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  #x = tf.keras.layers.Conv2D(64, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "  # This is the last layer of the model\n",
        "  #last = tf.keras.layers.Conv2DTranspose(output_channels, 3, strides=2,padding='same')  #64x64 -> 128x128\n",
        "\n",
        "  \n",
        "  last = tf.keras.layers.Conv2DTranspose(output_channels, 3, strides=2,padding='same', activation='softmax')  #64x64 -> 128x128\n",
        "  x = last(x)\n",
        "\n",
        "  #x = tf.keras.layers.Conv2DTranspose(output_channels, 3, strides=2,padding='same', activation='relu')(x)\n",
        "  #x = tf.keras.layers.Concatenate()([x, skips[0]])\n",
        "  #x = tf.keras.layers.Conv2D(3, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZiehK-RSQyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_CHANNELS = 3\n",
        "model = unet_model(OUTPUT_CHANNELS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWD3cjMx8bL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce6EWjEymhX3",
        "colab_type": "text"
      },
      "source": [
        "# Тип 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHZ6QjQg66wf",
        "colab_type": "text"
      },
      "source": [
        "EfficientNetB0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub3bpgq_HYgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install -U git+https://github.com/qubvel/efficientnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IsVOD2yZMtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# будет работать с элементами tensoflow.keras\n",
        "import efficientnet.tfkeras as efn\n",
        "\n",
        "# будет работать с элементами keras\n",
        "#import efficientnet.keras as efn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZF3doNBblVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2axoD5eTHaYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = efn.EfficientNetB0(weights='imagenet', input_shape=[128, 128, 3], include_top=False)  # or weights='noisy-student'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skklnwh8IoVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PtGhsX_DLQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 30.06.2020 лучше дергать скипы из слоев энкодера с меньшим количеством каналов (получилось\n",
        "# быстрее и точнее), и при этом после каждой конкатенации применять конволюцию"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLBJcIOf3oTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the activations of these layers\n",
        "\n",
        "# Берем слои с меньшим количеством каналов (из энкодера)\n",
        "layer_names = [\n",
        "    'stem_conv',   # 64x64 32\n",
        "    'block2b_add',   # 32x32 24\n",
        "    'block3b_add',   # 16x16 40\n",
        "    'block5c_add',  # 8x8 112\n",
        "    'top_activation',      # 4x4 1280 (top)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxDktnc-3lqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Берем слои с бОльшим количетсвом каналов (из энкодера)\n",
        "layer_names = [\n",
        "    'block2a_expand_conv',   # 64x64 96\n",
        "    'block2b_expand_conv',   # 32x32 144\n",
        "    'block3b_expand_conv',   # 16x16 240\n",
        "    'block4b_expand_conv',  # 8x8 480\n",
        "    'top_activation',      # 4x4 1280 (top)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFZCE2-UM96W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = [model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "down_stack = tf.keras.Model(inputs=model.input, outputs=layers)\n",
        "\n",
        "down_stack.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBmiqnKcQswm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1PZ0zvVOvjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1twvpnAL3_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJsi4JSfE_Q3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Соответствует слоям с меньшим количеством каналов \n",
        "\n",
        "up_stack = [\n",
        "    pix2pix.upsample(224, 3),  # 4x4 -> 8x8\n",
        "    pix2pix.upsample(80, 3),  # 8x8 -> 16x16\n",
        "    pix2pix.upsample(48, 3),  # 16x16 -> 32x32\n",
        "    pix2pix.upsample(32, 3),   # 32x32 -> 64x64\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q88ETMgnUCb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Соответствует слоям с бОльшим количеством каналов \n",
        "\n",
        "up_stack = [\n",
        "    pix2pix.upsample(480, 3),  # 4x4 -> 8x8\n",
        "    pix2pix.upsample(240, 3),  # 8x8 -> 16x16\n",
        "    pix2pix.upsample(144, 3),  # 16x16 -> 32x32\n",
        "    pix2pix.upsample(96, 3),   # 32x32 -> 64x64\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj05xDhnUD2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Замутить хитрую инициализацию весов и swish\n",
        "\n",
        "def unet_model(output_channels):\n",
        "  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
        "  x = inputs\n",
        "\n",
        "  # Downsampling through the model\n",
        "  skips = down_stack(x)\n",
        "  x = skips[-1]\n",
        "\n",
        "  x = tf.keras.layers.Conv2D(512, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  x = tf.keras.layers.Conv2D(256, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "  x = up_stack[0](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[3]])\n",
        "  x = tf.keras.layers.Conv2D(128, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  #x = tf.keras.layers.Conv2D(64, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "  x = up_stack[1](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[2]])\n",
        "  x = tf.keras.layers.Conv2D(64, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  #x = tf.keras.layers.Conv2D(32, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "  x = up_stack[2](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[1]])\n",
        "  x = tf.keras.layers.Conv2D(64, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  #x = tf.keras.layers.Conv2D(32, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "  x = up_stack[3](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[0]])\n",
        "  x = tf.keras.layers.Conv2D(16, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  #x = tf.keras.layers.Conv2D(8, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "  # This is the last layer of the model\n",
        "  #last = tf.keras.layers.Conv2DTranspose(output_channels, 3, strides=2,padding='same')  #64x64 -> 128x128\n",
        "\n",
        "  \n",
        "  last = tf.keras.layers.Conv2DTranspose(output_channels, 3, strides=2,padding='same', activation='softmax')  #64x64 -> 128x128\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTeIL3TAVPca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_CHANNELS = 3\n",
        "model = unet_model(OUTPUT_CHANNELS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-3RG8xz7CbJ",
        "colab_type": "text"
      },
      "source": [
        "## ТИП 5 - самый лучший вариант"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1MUestU7XhS",
        "colab_type": "text"
      },
      "source": [
        "EfficientNetB4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AfsigVN7QFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install -U git+https://github.com/qubvel/efficientnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEf1ivmT7egm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import efficientnet.tfkeras as efn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB5lhXoI7oku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = efn.EfficientNetB4(weights='imagenet', input_shape=[128, 128, 3], include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI9Oee9r7oo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-F9B1fv9nd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_names = [\n",
        "    'stem_conv',   # 64x64 48\n",
        "    'block2b_add',   # 32x32 32\n",
        "    'block3b_add',   # 16x16 56\n",
        "    'block5c_add',  # 8x8 160\n",
        "    'top_activation',      # 4x4 1792 (top)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItYtYjll7oug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P4ElAvB9Mm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = [model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "down_stack = tf.keras.Model(inputs=model.input, outputs=layers)\n",
        "\n",
        "down_stack.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toy6DoIi_UE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Замутить хитрую инициализацию весов и swish\n",
        "\n",
        "def unet_model(output_channels):\n",
        "  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
        "  x = inputs\n",
        "\n",
        "  # Downsampling through the model\n",
        "  skips = down_stack(x)\n",
        "  x = skips[-1]\n",
        "\n",
        "  #x = tf.keras.layers.Conv2D(1024, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  x = tf.keras.layers.Conv2D(512, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  x = tf.keras.layers.Conv2D(256, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "  x = up_stack[0](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[3]])\n",
        "  x = tf.keras.layers.Conv2D(128, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "\n",
        "  x = up_stack[1](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[2]])\n",
        "  x = tf.keras.layers.Conv2D(64, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "\n",
        "  x = up_stack[2](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[1]])\n",
        "  x = tf.keras.layers.Conv2D(64, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "\n",
        "  x = up_stack[3](x)\n",
        "  x = tf.keras.layers.Concatenate()([x, skips[0]])\n",
        "  x = tf.keras.layers.Conv2D(32, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "  x = tf.keras.layers.Conv2D(16, 3, strides=(1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "\n",
        "  # This is the last layer of the model\n",
        "  #last = tf.keras.layers.Conv2DTranspose(output_channels, 3, strides=2,padding='same')  #64x64 -> 128x128\n",
        "\n",
        "  \n",
        "  last = tf.keras.layers.Conv2DTranspose(output_channels, 3, strides=2,padding='same', activation='softmax')  #64x64 -> 128x128\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSRv-dRJ_fNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_CHANNELS = 3\n",
        "model = unet_model(OUTPUT_CHANNELS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMVf2PGIWSBj",
        "colab_type": "text"
      },
      "source": [
        "## Тренировка модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5_7GGyHWQeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVjCr5UsWluT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tc3MiEO2twLS"
      },
      "source": [
        "Давайте попробуем сделать предсказание с помощью нашей модели до того как началось обучение."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UwvIKLZPtxV_",
        "colab": {}
      },
      "source": [
        "def create_mask(pred_mask):\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  return pred_mask[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YLNsrynNtx4d",
        "colab": {}
      },
      "source": [
        "def show_predictions(dataset=None, num=1):\n",
        "  if dataset:\n",
        "    for image, mask in dataset.take(num):\n",
        "      pred_mask = model.predict(image)\n",
        "      display([image[0], mask[0], create_mask(pred_mask)])\n",
        "  else:\n",
        "    display([sample_image, sample_mask,\n",
        "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X_1CC0T4dho3",
        "colab": {}
      },
      "source": [
        "show_predictions()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "22AyVYWQdkgk"
      },
      "source": [
        "Давайте осуществлять мониторинг того как улучшается работа модели в процессе обучения. Для завершения этой задачи callback функция определена ниже."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wHrHsqijdmL6",
        "colab": {}
      },
      "source": [
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    clear_output(wait=True)\n",
        "    show_predictions()\n",
        "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "StKDH_B9t4SD",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "VAL_SUBSPLITS = 5\n",
        "VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
        "\n",
        "model_history = model.fit(train_dataset, epochs=EPOCHS,\n",
        "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                          validation_steps=VALIDATION_STEPS,\n",
        "                          validation_data=test_dataset,\n",
        "                          callbacks=[DisplayCallback()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P_mu0SAbt40Q",
        "colab": {}
      },
      "source": [
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "\n",
        "epochs = range(EPOCHS)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "unP3cnxo_N72"
      },
      "source": [
        "## Предсказание\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7BVXldSo-0mW"
      },
      "source": [
        "Давайте сделаем несколько предсказаний. Для экономии времени использовалось небольшое количество эпох, но вы можете его увеличить для того чтобы модель давала более точные результаты."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ikrzoG24qwf5",
        "colab": {}
      },
      "source": [
        "show_predictions(test_dataset, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppTwyfnMpaB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}