{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro_NN_article.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqaswE2BgO_M",
        "colab_type": "text"
      },
      "source": [
        "## Обзор сейронной сети YOLO v4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZtuLS8DI_Ym",
        "colab_type": "text"
      },
      "source": [
        "Наиболее точные нейросети не способны работать в режиме реального времени и требуют большого количества GPU юнитов для обучения совместно с большим размером батчей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVtTOW4DJiYr",
        "colab_type": "text"
      },
      "source": [
        "Разработчики YOLO v4 решили проблему путем создания CNN, которая работает в режиме реального времени на обычном графическом процессоре и для обучения которой  требуется только один неспециализированный графический процессор."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfiAiMlE-vvf",
        "colab_type": "text"
      },
      "source": [
        "Авторами предложен современный детектор, который быстрее (FPS) и точнее (MS COCO AP50 ... 95 и AP50), чем все доступные альтернативные детекторы. Он может быть обучен и использован на обычном графическом процессоре с 8-16 GB-VRAM, что делает возможным его широкое использование. Авторами предложены различные подходы для увеличения точности и производительности как алгоритмов классификации, так и детекции. Эти подходы могут быть использованы в будущих исследованиях и разработках."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXJNxRzhBatD",
        "colab_type": "text"
      },
      "source": [
        "YOLO v4 состоит из:\n",
        "\n",
        "1.   В качестве backbone для извлечения признаков CSPDarknet53;\n",
        "2.   Для работы с признаками разного масштаба SPP (spatial pyramid pooling layer) и Path Aggregation Network (PAN);\n",
        "3.   YOLO v3 для предсказания класса и локализации объектов.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnBetG4xGDEb",
        "colab_type": "text"
      },
      "source": [
        "YOLO v4 использует:\n",
        "\n",
        "1. Bag of Freebies (BoF) для backbone: CutMix и\n",
        "Mosaic аугментации, DropBlock регуляризацию,\n",
        "Class label smoothing;\n",
        "2. Bag of Specials (BoS) для backbone: функцию активации Mish, Cross-stage partial connections (CSP), Multiinput weighted residual connections (MiWRC);\n",
        "3. Bag of Freebies (BoF) для detector: CIoU-функцию потерь,\n",
        "CmBN, DropBlock регуляризацию, Mosaic аугментацию, Self-Adversarial Training, Eliminate grid sensitivity, использование нескольких якорей для одного правильного ответа, уменьшение скорости обучения по косинусу, оптимальные гиперпараметры, множество различных тренировок;\n",
        "4. Bag of Specials (BoS) for detector: функцию активации Mish,\n",
        "SPP-блок, SAM-блок, PAN блок агрегации,DIoU-NMS.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPLsYjXdKf2V",
        "colab_type": "text"
      },
      "source": [
        "В совокупности это позволяет YOLOv4 достигать точности 43.5% AP / 65.7% AP50 на тесте Microsoft COCO при скорости 62 FPS TitanV или 34 FPS RTX 2070. В отличии от других современных детекторов, YOLOv4 может обучить любой, у кого есть игровая видеокарта nVidia с 8-16 GB VRAM. Теперь не только крупные компании могут обучать нейронную сеть на сотнях GPU / TPU с использованием больших размеров mini-batch для достижения более высокой точности. Теперь и обычные и пользователи могут обучать точные алгоритмы детекции, потому что для YOLOv4 большой размер батча не требуется (можно ограничиться размером 2 – 8)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS_D_n46OUv7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "YOLOv4 работает в 2 раза быстрее, чем EfficientDet с такой же точностью. YOLOv4 превосходит YOLOv3 по AP и FPS на 10% и 12% соответственно. YOLOv4 требует в 5 раза более дешевое оборудование и при этом точнее, чем EfficientDet-D2 (Google-TensorFlow). Можно использовать EfficientDet-D0 (Google-TensorFlow) тогда стоимость оборудования будет одинаковая, но точность будет на 10% AP ниже."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ciy47DitPFMK",
        "colab_type": "text"
      },
      "source": [
        "YOLOv4 достаточно обучить один раз с разрешением изображения 512x512, и затем можно использовать с разными разрешениями в диапазоне: [416x416 – 512x512 – 608x608]. Большинство же других моделей требуется обучать каждый раз отдельно для каждого разрешения, из-за этого обучение занимает в разы больше времени."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PgGb2ymqUsC",
        "colab_type": "text"
      },
      "source": [
        "Источники: \n",
        "\n",
        "1.   https://habr.com/ru/post/503200/\n",
        "2.   https://arxiv.org/pdf/2004.10934.pdf\n",
        "3.   https://medium.com/@jonathan_hui/yolov4-c9901eaa8e61\n",
        "\n",
        "\n"
      ]
    }
  ]
}