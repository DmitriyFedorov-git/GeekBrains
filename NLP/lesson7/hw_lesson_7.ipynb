{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "hw_lesson_7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXTVHzNy8DjH"
      },
      "source": [
        "# Домашнее задание №7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oiHprND8NmN"
      },
      "source": [
        "Урок 7. Модель Transformer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX0xVRwv6Pba"
      },
      "source": [
        "Запустить seq2seq, seq2seq с внимаием для перевода русских слов + описать наблюдения по качеству\n",
        "Данные в папке data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdczynAsl5_C"
      },
      "source": [
        "## Sec2sec with attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBe1aNp-xnIN"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyJ915G1yv8I"
      },
      "source": [
        "import re\n",
        "import tensorflow.compat.v1 as tf\n",
        "data_path = 'rus.txt'\n",
        "num_samples = 10000\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,¿]+\", \" \", w)\n",
        "    w = w.strip()\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(preprocess_sentence(input_text))\n",
        "    target_texts.append(preprocess_sentence(target_text))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jE0BDxCgy6KR"
      },
      "source": [
        "def tokenize(lang):\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "    return tensor, lang_tokenizer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCi4vN4EzCux"
      },
      "source": [
        "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
        "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iTPqdDpzFJt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzFZljNwzHee"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "\n",
        "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
        "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxThQ3vLzKc9"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.lstm(x, initial_state = hidden)\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "    \n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "            self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "    \n",
        "    \n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output, state = self.lstm(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.fc(output)\n",
        "        return x, state, attention_weights"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUTXpfKizP2V"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6UQqD4BzSq2"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "    \n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdV7Vye-zVOu",
        "outputId": "7aec6914-e869-4e96-b9c2-bfc3ba9e4e12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "EPOCHS = 30\n",
        "for epoch in range(EPOCHS):\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 1.6559\n",
            "Epoch 2 Loss 1.2371\n",
            "Epoch 3 Loss 1.0686\n",
            "Epoch 4 Loss 0.9366\n",
            "Epoch 5 Loss 0.8121\n",
            "Epoch 6 Loss 0.6901\n",
            "Epoch 7 Loss 0.5792\n",
            "Epoch 8 Loss 0.4777\n",
            "Epoch 9 Loss 0.3913\n",
            "Epoch 10 Loss 0.3289\n",
            "Epoch 11 Loss 0.2809\n",
            "Epoch 12 Loss 0.2436\n",
            "Epoch 13 Loss 0.2176\n",
            "Epoch 14 Loss 0.2008\n",
            "Epoch 15 Loss 0.1855\n",
            "Epoch 16 Loss 0.1734\n",
            "Epoch 17 Loss 0.1652\n",
            "Epoch 18 Loss 0.1578\n",
            "Epoch 19 Loss 0.1544\n",
            "Epoch 20 Loss 0.1484\n",
            "Epoch 21 Loss 0.1468\n",
            "Epoch 22 Loss 0.1429\n",
            "Epoch 23 Loss 0.1387\n",
            "Epoch 24 Loss 0.1364\n",
            "Epoch 25 Loss 0.1348\n",
            "Epoch 26 Loss 0.1332\n",
            "Epoch 27 Loss 0.1323\n",
            "Epoch 28 Loss 0.1303\n",
            "Epoch 29 Loss 0.1288\n",
            "Epoch 30 Loss 0.1272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEsExegszXsG"
      },
      "source": [
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    result = ''\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    return result, sentence, attention_plot\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    fontdict = {'fontsize': 14}\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "    #ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    #ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    plt.show()\n",
        "    \n",
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yz16s2_2G_F",
        "outputId": "240f422b-4393-46d8-f295-f7091ae0777c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        }
      },
      "source": [
        "%pylab inline\n",
        "\n",
        "translate(u'today was a good day')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n",
            "Input: <start> today was a good day <end>\n",
            "Predicted translation: это было есть нет ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njX4Jtd1nnjN"
      },
      "source": [
        "## Sec2sec without attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucUi5DQhno0X"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        #self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        #context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        x = self.embedding(x)\n",
        "        #x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output, state = self.lstm(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.fc(output)\n",
        "        return x, state#, attention_weights"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GswwkWzEoW7_"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWF2DmkGq6zw"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_output)\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "    \n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7_X1r6Dods7",
        "outputId": "bca88d9e-51fd-482a-d146-8d93c775a209",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "EPOCHS = 30\n",
        "for epoch in range(EPOCHS):\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['encoder_2/embedding_4/embeddings:0', 'encoder_2/gru_4/gru_cell_4/kernel:0', 'encoder_2/gru_4/gru_cell_4/recurrent_kernel:0', 'encoder_2/gru_4/gru_cell_4/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['encoder_2/embedding_4/embeddings:0', 'encoder_2/gru_4/gru_cell_4/kernel:0', 'encoder_2/gru_4/gru_cell_4/recurrent_kernel:0', 'encoder_2/gru_4/gru_cell_4/bias:0'] when minimizing the loss.\n",
            "Epoch 1 Loss 1.9305\n",
            "Epoch 2 Loss 1.3672\n",
            "Epoch 3 Loss 1.2900\n",
            "Epoch 4 Loss 1.2293\n",
            "Epoch 5 Loss 1.1764\n",
            "Epoch 6 Loss 1.1320\n",
            "Epoch 7 Loss 1.0940\n",
            "Epoch 8 Loss 1.0619\n",
            "Epoch 9 Loss 1.0351\n",
            "Epoch 10 Loss 1.0141\n",
            "Epoch 11 Loss 0.9967\n",
            "Epoch 12 Loss 0.9821\n",
            "Epoch 13 Loss 0.9718\n",
            "Epoch 14 Loss 0.9634\n",
            "Epoch 15 Loss 0.9560\n",
            "Epoch 16 Loss 0.9520\n",
            "Epoch 17 Loss 0.9478\n",
            "Epoch 18 Loss 0.9440\n",
            "Epoch 19 Loss 0.9417\n",
            "Epoch 20 Loss 0.9392\n",
            "Epoch 21 Loss 0.9371\n",
            "Epoch 22 Loss 0.9354\n",
            "Epoch 23 Loss 0.9333\n",
            "Epoch 24 Loss 0.9324\n",
            "Epoch 25 Loss 0.9308\n",
            "Epoch 26 Loss 0.9299\n",
            "Epoch 27 Loss 0.9294\n",
            "Epoch 28 Loss 0.9281\n",
            "Epoch 29 Loss 0.9274\n",
            "Epoch 30 Loss 0.9262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64p7afr5rBXz"
      },
      "source": [
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    result = ''\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_out)\n",
        "       \n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    return result, sentence\n",
        "    \n",
        "def translate(sentence):\n",
        "    result, sentence = evaluate(sentence)\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vKJYBaTsEuS",
        "outputId": "6b899695-0b18-4700-9a08-f87f2e5120e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%pylab inline\n",
        "\n",
        "translate(u'today was a good day')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n",
            "Input: <start> today was a good day <end>\n",
            "Predicted translation: я не могу я не могу я не могу я не могу \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXY3GWFu74BA"
      },
      "source": [
        "Sec2sec с вниманием дает лучший результат: видно по loss и переводу текста"
      ]
    }
  ]
}