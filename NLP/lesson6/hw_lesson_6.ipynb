{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "hw_lesson_6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXTVHzNy8DjH"
      },
      "source": [
        "# Домашнее задание №6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oiHprND8NmN"
      },
      "source": [
        "Урок 6. Рекуррентные нейронные сети. LSTM. GRU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX0xVRwv6Pba"
      },
      "source": [
        "Провести сравнение RNN, LSTM, GRU на датасете отзывов (из предыдущих занятий/материалов)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdczynAsl5_C"
      },
      "source": [
        "## Загрузка данных и библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAWk9kU0mrdw",
        "outputId": "b39e5e29-a798-4b29-c303-2f91ee4ee867",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install stop_words\n",
        "!pip install pymorphy2 "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stop_words\n",
            "  Downloading https://files.pythonhosted.org/packages/1c/cb/d58290804b7a4c5daa42abbbe2a93c477ae53e45541b1825e86f0dfaaf63/stop-words-2018.7.23.tar.gz\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-cp36-none-any.whl size=32916 sha256=a6a454c3fcc60d8495bbf2afe6caad0f16e1b54639b66541f9011a174c96b02e\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/37/6a/2b295e03bd07290f0da95c3adb9a74ba95fbc333aa8b0c7c78\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n",
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.0MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Installing collected packages: dawg-python, pymorphy2-dicts-ru, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRtu2KiLXql6",
        "outputId": "f0590579-804d-430c-e4ad-231638fec76f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn import model_selection, preprocessing, metrics\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "import re\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.objectives import categorical_crossentropy\n",
        "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, MaxPooling1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import optimizers\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from stop_words import get_stop_words\n",
        "from string import punctuation\n",
        "from gensim.models import Word2Vec\n",
        "nltk.download(\"punkt\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIDobiQNjzga"
      },
      "source": [
        "# Устанавливаем гиперпараметры\n",
        "epochs = 10\n",
        "batch_size = 512"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCu2bz1bJwlZ"
      },
      "source": [
        "## Предобработка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPK4e9uVzDQv"
      },
      "source": [
        "data = pd.read_excel('summer.xls')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eozCaEPvUo0",
        "outputId": "baa4ea5b-b966-47af-f022-a19ffdde77c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "exclude = set(punctuation)\n",
        "stop_words = set(get_stop_words(\"ru\"))\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in stop_words]\n",
        "    return \" \".join(txt)\n",
        "\n",
        "# Делаем предобработку и сокращаем количество классов до 2\n",
        "data['text'] = data['Content'].apply(preprocess_text)\n",
        "data = data[data['Rating'] != 3]\n",
        "data['target'] = data['Rating'] > 3\n",
        "data['target'] = data['target'].astype(int)\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Content</th>\n",
              "      <th>Date</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>It just works!</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>it just works</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>целое удобноной приложениеиз минус хотеть боль...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Отлично все</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>отлично</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>зависать 1 работа антивирус ранее пользоваться...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Очень удобно, работает быстро.</td>\n",
              "      <td>2017-08-14</td>\n",
              "      <td>удобно работать быстро</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rating  ... target\n",
              "0       5  ...      1\n",
              "1       4  ...      1\n",
              "2       5  ...      1\n",
              "3       5  ...      1\n",
              "4       5  ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwvx4_-RwFs7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['target'], test_size=0.2,\n",
        "                                                    random_state=13, stratify=data['target'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK2zujL_997j"
      },
      "source": [
        "text_corpus_train = X_train.values\n",
        "text_corpus_test = X_test.values"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBmg3NMURfmg"
      },
      "source": [
        "## Токенизация и векторизация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT6nE2MC-ey2"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=None, \n",
        "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
        "                     lower = False, split = ' ')\n",
        "tokenizer.fit_on_texts(text_corpus_train)\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(text_corpus_test)\n",
        "\n",
        "word_count = len(tokenizer.index_word) + 1\n",
        "training_length = max([len(i.split()) for i in text_corpus_train])\n",
        "\n",
        "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
        "X_test = pad_sequences(sequences_test, maxlen=training_length)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ludAbTWn_INn"
      },
      "source": [
        "y_train = y_train.values\n",
        "y_test = y_test.values"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vndX8m3889iH"
      },
      "source": [
        "## Обучение RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jwVPc-K_XO1",
        "outputId": "3d8f7d2a-a3c6-4d7c-ba8a-07ded4f6278c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=64,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=[keras.metrics.AUC()])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "28/28 [==============================] - 5s 190ms/step - loss: 0.4368 - auc: 0.6878 - val_loss: 0.3264 - val_auc: 0.9028\n",
            "Epoch 2/10\n",
            "28/28 [==============================] - 5s 176ms/step - loss: 0.2862 - auc: 0.8713 - val_loss: 0.2518 - val_auc: 0.9317\n",
            "Epoch 3/10\n",
            "28/28 [==============================] - 5s 184ms/step - loss: 0.2091 - auc: 0.9368 - val_loss: 0.2172 - val_auc: 0.9486\n",
            "Epoch 4/10\n",
            "28/28 [==============================] - 5s 175ms/step - loss: 0.1404 - auc: 0.9737 - val_loss: 0.2089 - val_auc: 0.9505\n",
            "Epoch 5/10\n",
            "28/28 [==============================] - 5s 179ms/step - loss: 0.0992 - auc: 0.9862 - val_loss: 0.2391 - val_auc: 0.9436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnKOZ6sA96AM",
        "outputId": "7c0ffe1a-7137-41c8-b5d3-f6fdcee9be1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 16ms/step - loss: 0.2037 - auc_9: 0.9539\n",
            "\n",
            "\n",
            "Test score: 0.2037380039691925\n",
            "Test accuracy: 0.9538590908050537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amHcvp_sDryR"
      },
      "source": [
        "## Обучение LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrXBF0xcDq1z",
        "outputId": "5e7561e4-75bb-44d1-db24-086d8b89ca9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=64,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "\n",
        "model.add(LSTM(64, recurrent_dropout=0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=[keras.metrics.AUC()])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/10\n",
            "28/28 [==============================] - 14s 518ms/step - loss: 0.4775 - auc_8: 0.6058 - val_loss: 0.3323 - val_auc_8: 0.9106\n",
            "Epoch 2/10\n",
            "28/28 [==============================] - 14s 496ms/step - loss: 0.2856 - auc_8: 0.8825 - val_loss: 0.2410 - val_auc_8: 0.9288\n",
            "Epoch 3/10\n",
            "28/28 [==============================] - 14s 501ms/step - loss: 0.2097 - auc_8: 0.9426 - val_loss: 0.2100 - val_auc_8: 0.9491\n",
            "Epoch 4/10\n",
            "28/28 [==============================] - 14s 491ms/step - loss: 0.1513 - auc_8: 0.9715 - val_loss: 0.2064 - val_auc_8: 0.9501\n",
            "Epoch 5/10\n",
            "28/28 [==============================] - 14s 503ms/step - loss: 0.1091 - auc_8: 0.9840 - val_loss: 0.2178 - val_auc_8: 0.9458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT_1dovyECmH",
        "outputId": "730f02a4-c821-46dc-c7c4-6dfc5839ff65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 39ms/step - loss: 0.1973 - auc_8: 0.9545\n",
            "\n",
            "\n",
            "Test score: 0.19731782376766205\n",
            "Test accuracy: 0.9545498490333557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3zky0MvE1wn"
      },
      "source": [
        "## Обучение GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DESrw3MIExcR",
        "outputId": "fc94b6c0-15cf-4458-d813-4970569acbe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=64,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "\n",
        "model.add(GRU(64, recurrent_dropout=0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=[keras.metrics.AUC()])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "28/28 [==============================] - 2s 89ms/step - loss: 0.5164 - auc_10: 0.5702 - val_loss: 0.3270 - val_auc_10: 0.9105\n",
            "Epoch 2/10\n",
            "28/28 [==============================] - 1s 45ms/step - loss: 0.2831 - auc_10: 0.9039 - val_loss: 0.2386 - val_auc_10: 0.9302\n",
            "Epoch 3/10\n",
            "28/28 [==============================] - 1s 46ms/step - loss: 0.2025 - auc_10: 0.9463 - val_loss: 0.2136 - val_auc_10: 0.9452\n",
            "Epoch 4/10\n",
            "28/28 [==============================] - 1s 46ms/step - loss: 0.1479 - auc_10: 0.9715 - val_loss: 0.2137 - val_auc_10: 0.9471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plx12DwjFidM",
        "outputId": "cdb7ffab-35f5-4ee3-fa2b-a4adad5f16f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 21ms/step - loss: 0.1948 - auc_10: 0.9570\n",
            "\n",
            "\n",
            "Test score: 0.19481970369815826\n",
            "Test accuracy: 0.9570112228393555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDbnThVyJY4G"
      },
      "source": [
        "Наилучший результат дает модель GRU, при этом она обучается быстрее LSTM. RNN дает высокий результат, потому что последовательности имеют небольшой размер"
      ]
    }
  ]
}